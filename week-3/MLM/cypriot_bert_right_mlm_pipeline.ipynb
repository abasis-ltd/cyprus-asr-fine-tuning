{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h96mnJkxApwF"
      },
      "outputs": [],
      "source": [
        "!pip install datasets==3.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiBKLukoBC9g"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import torch\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.getLogger(\"pyngrok\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"torch\").setLevel(logging.ERROR)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MS8_SWlHBEXv"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG3MfxypBFtE"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Dataset, Audio\n",
        "\n",
        "ds_cy = load_dataset(\"Elormiden/Thesaurus-Cypriot-Greek-Dialect\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pu4h3ujBJ-z"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"google-bert/bert-base-multilingual-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlLUZRy9BcXf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Dividing our initial dataset by columns\n",
        "\"\"\"\n",
        "train_cy = ds_cy['train']\n",
        "val_cy = ds_cy['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5TC3Dt6ChKu"
      },
      "outputs": [],
      "source": [
        "def tokenize_for_mlm(batch):\n",
        "    tokenized_texts = []\n",
        "\n",
        "    for word, description, greek_word, greek_desc in tqdm(\n",
        "        zip(batch['word'], batch['description'], batch['greek_word'], batch['greek_description']),\n",
        "        total=len(batch['word']), desc=\"Tokenizing for MLM\"):\n",
        "\n",
        "        full_text = f\"{word} - {description} [SEP] {greek_word} - {greek_desc}\"\n",
        "        tokenized_texts.append(tokenizer.encode(\n",
        "            full_text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512,           # ← 512 is the limit\n",
        "            truncation=True\n",
        "            )\n",
        "        )\n",
        "\n",
        "    input_ids_tensors = [torch.tensor(ids, dtype=torch.long) for ids in tokenized_texts]\n",
        "    input_ids_padded = pad_sequence(input_ids_tensors, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    input_ids_masked, labels = mask_tokens(input_ids_padded, tokenizer, mlm_probability=0.15)\n",
        "    attention_mask = (input_ids_masked != tokenizer.pad_token_id).long()\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids_masked,  # С [MASK] токенам\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"labels\": labels\n",
        "    }\n",
        "\n",
        "def mask_tokens(inputs, tokenizer, mlm_probability=0.15):\n",
        "    labels = inputs.clone()\n",
        "\n",
        "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
        "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
        "\n",
        "    special_tokens_mask = torch.zeros_like(labels, dtype=torch.bool)\n",
        "    for token_id in [tokenizer.pad_token_id, tokenizer.cls_token_id, tokenizer.sep_token_id]:\n",
        "        special_tokens_mask |= (labels == token_id)\n",
        "\n",
        "    masked_indices &= ~special_tokens_mask\n",
        "\n",
        "    labels[~masked_indices] = -100\n",
        "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
        "    inputs[indices_replaced] = tokenizer.mask_token_id\n",
        "\n",
        "    return inputs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci2gf1ZKEBvD"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Filling into the function\n",
        "\"\"\"\n",
        "train_cyprus_tokenized = tokenize_for_mlm(train_cy)\n",
        "val_cyprus_tokenized = tokenize_for_mlm(val_cy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFIN0tTaFaqr"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Converting dicts to Dataset HuggingFace format\n",
        "\"\"\"\n",
        "train_hf = Dataset.from_dict(train_cyprus_tokenized)\n",
        "val_hf = Dataset.from_dict(val_cyprus_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3uL0BYMEySe"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"./cypriot-corrector-bert-mlm-lr5e-5-batch16\",\n",
        "    num_train_epochs=8,\n",
        "    \n",
        "    ################# \n",
        "    per_device_train_batch_size=16,        \n",
        "    per_device_eval_batch_size=16,         \n",
        "    gradient_accumulation_steps=1,       \n",
        "    ################\n",
        "    \n",
        "    learning_rate=5e-5,\n",
        "    warmup_steps=1000,\n",
        "    \n",
        "    #################### A100 \n",
        "    gradient_checkpointing=False,        \n",
        "    bf16=True,                           \n",
        "    dataloader_pin_memory=True,        \n",
        "    dataloader_num_workers=4,            \n",
        "    #################\n",
        "    \n",
        "    save_steps=200,\n",
        "    eval_steps=50,                      \n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to='wandb',\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    logging_steps=50,                    \n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_hf,\n",
        "    eval_dataset=val_hf,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL1ZXXrKE9mX"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
