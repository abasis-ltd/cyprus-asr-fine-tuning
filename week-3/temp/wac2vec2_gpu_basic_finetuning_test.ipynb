{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install ipywidgets # huggin face widgets\n",
        "# !pip install --upgrade timm # timm error gpu gemma 3n\n",
        "# !pip install torchcodec\n",
        "# !pip install librosa soundfile\n",
        "\n",
        "# # audio errors\n",
        "# !sudo apt update\n",
        "# !sudo apt install -y ffmpeg\n",
        "# !pip install --upgrade huggingface_hub\n",
        "\n",
        "# HF errors fix\n",
        "# !pip install datasets==3.6.0\n",
        "# !pip index versions datasets\n",
        "# !pip index versions numpy\n",
        "# !pip install huggingface-hub==0.20.0"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Sg8RJPL3Q8Ct"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "29pcuItpQ8Cu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "numpy.__version__"
      ],
      "metadata": {
        "trusted": true,
        "id": "MDB84KBmQ8Cv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install mlflow\n",
        "# !pip install pyngrok"
      ],
      "metadata": {
        "trusted": true,
        "id": "Puow4uvpQ8Cv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.getLogger(\"pyngrok\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"torch\").setLevel(logging.ERROR)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "trusted": true,
        "id": "7GKRPaAHQ8Cv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "uqZYCZVnQ8Cv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade datasets\n",
        "from transformers import AutoProcessor, AutoModelForCTC, Trainer, TrainingArguments, DataCollatorWithPadding\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "trusted": true,
        "id": "w45eLWetQ8Cx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"el\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "3Xvjr0mlQ8Cy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "trusted": true,
        "id": "GXW5wsrGQ8Cy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_type_tester(dataset):\n",
        "    sample = dataset['train'][0]\n",
        "    audio_decoder = sample['audio']\n",
        "\n",
        "    print(\"Attributes of AudioDecoder:\")\n",
        "    print([attr for attr in dir(audio_decoder) if not attr.startswith('_')])\n",
        "\n",
        "    if hasattr(audio_decoder, 'path'):\n",
        "        print(f\"Path type: {type(audio_decoder.path)}\")\n",
        "        print(f\"Path content: {audio_decoder.path}\")\n",
        "\n",
        "    for attr in ['file', 'filename', 'source', 'metadata']:\n",
        "        if hasattr(audio_decoder, attr):\n",
        "            value = getattr(audio_decoder, attr)\n",
        "            print(f\"{attr}: {type(value)} = {value}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "Z5yMx0uBQ8Cy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "audio_type_tester(ds)"
      ],
      "metadata": {
        "trusted": true,
        "id": "D17leb8yQ8Cz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoProcessor, AutoModelForCTC\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"jonatasgrosman/wav2vec2-large-xlsr-53-greek\")\n",
        "model = AutoModelForCTC.from_pretrained(\"jonatasgrosman/wav2vec2-large-xlsr-53-greek\").eval()"
      ],
      "metadata": {
        "trusted": true,
        "id": "mkRfpToWQ8Cz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model vocab size: {model.config.vocab_size}\")\n",
        "print(f\"Processor vocab: {len(processor.tokenizer.get_vocab())}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "17D2sKcfQ8Cz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sample = ds['train'][0]\n",
        "print(f\"Sample keys: {sample.keys()}\")\n",
        "print(f\"Audio type: {type(sample['audio'])}\")\n",
        "print(f\"Sentence: {sample['sentence']}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "fSDnziigQ8Cz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# sample = ds['train'][3]\n",
        "# sr = sample['audio']['sampling_rate'] # -> sampling rate\n",
        "# tr = 16000\n",
        "\n",
        "# saved_example = sample\n",
        "# print(f\"Before: {sample['audio']}\")\n",
        "# resample_sample = librosa.resample(sample['audio']['array'], orig_sr=sr, target_sr=tr)\n",
        "# saved_example['audio'] = {\n",
        "#     'path': sample['audio']['path'],\n",
        "#     'array': resample_sample,\n",
        "#     'sampling_rate': tr\n",
        "# }\n",
        "# print(f\"After: {saved_example['audio']}\")\n",
        "\n",
        "# Now we will resample the whole dataset to 16k sampling rate\n",
        "def sampling_map(array): # <- ds [train] goes here\n",
        "    saved_array = array\n",
        "    sr = array['audio']['sampling_rate']\n",
        "    tr = 16000\n",
        "    resample_array = librosa.resample(array['audio']['array'], orig_sr=sr, target_sr=tr)\n",
        "    saved_array['audio'] = {\n",
        "        'path': array['audio']['path'],\n",
        "        'array': resample_array,\n",
        "        'sampling_rate': tr\n",
        "    }\n",
        "    return saved_array"
      ],
      "metadata": {
        "trusted": true,
        "id": "t10SdKo-Q8Cz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import copy"
      ],
      "metadata": {
        "trusted": true,
        "id": "RaMv1aaOQ8Cz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "reforged_train = [sampling_map(sample) for sample in tqdm(ds['train'], desc=\"Resampling\")]\n",
        "reforged_eval = [sampling_map(sample) for sample in tqdm(ds['validation'], desc=\"Resampling\")]"
      ],
      "metadata": {
        "trusted": true,
        "id": "V8fwXzxaQ8C0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "8j3hG8KQQ8C0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Collator is needed in order to solve the list/numpy problem\n",
        "data_collator = DataCollatorWithPadding(\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "6fcvo32QQ8C0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator"
      ],
      "metadata": {
        "trusted": true,
        "id": "KKfcJ3WXQ8C0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def process_reforged_list(sample_list):\n",
        "    audio_arrays = [sample[\"audio\"][\"array\"] for sample in sample_list]\n",
        "    sentences = [sample[\"sentence\"] for sample in sample_list]\n",
        "\n",
        "    inputs = processor(\n",
        "        audio_arrays,\n",
        "        sampling_rate=16000,\n",
        "        padding=True,\n",
        "        max_length=16000,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    labels = processor.tokenizer(\n",
        "        sentences,\n",
        "        padding='max_length',\n",
        "        max_length=512,\n",
        "        truncation=True\n",
        "    )\n",
        "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
        "\n",
        "    return {\n",
        "        \"input_values\": inputs[\"input_values\"],\n",
        "        \"labels\": labels[\"input_ids\"]\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "id": "0LqGj3oMQ8C0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data_train = process_reforged_list(reforged_train)\n",
        "processed_data_eval = process_reforged_list(reforged_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "tlEbnKySQ8C0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(processed_data_train.keys())\n",
        "print(processed_data_eval.keys())"
      ],
      "metadata": {
        "trusted": true,
        "id": "JqJ_dXFtQ8C0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "train_hf = Dataset.from_dict(processed_data_train)\n",
        "eval_hf = Dataset.from_dict(processed_data_eval)"
      ],
      "metadata": {
        "trusted": true,
        "id": "WpLj-nx1Q8C0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== TRAIN DATASET ===\")\n",
        "print(f\"Размер: {len(train_hf)}\")\n",
        "print(f\"Колонки: {train_hf.column_names}\")\n",
        "print(f\"Features: {train_hf.features}\")\n",
        "\n",
        "print(\"\\n=== EVAL DATASET ===\")\n",
        "print(f\"Размер: {len(eval_hf)}\")\n",
        "print(f\"Колонки: {eval_hf.column_names}\")\n",
        "print(f\"Features: {eval_hf.features}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "3QCzdH_EQ8C0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/kaggle/working/wav2vec2-finetuned_mozilla',\n",
        "    run_name=\"wav2vec2-greek-asr\",  # ← Добавили уникальное имя\n",
        "    overwrite_output_dir=True,\n",
        "    max_steps=500,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=50,\n",
        "    save_total_limit=1,\n",
        "    prediction_loss_only=True,\n",
        "    fp16=True,\n",
        "    learning_rate=5e-6,\n",
        "    logging_steps=10,\n",
        "    # eval_strategy=\"steps\",\n",
        "    # eval_steps=50,\n",
        "    disable_tqdm=False,\n",
        "    report_to=[],\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_hf,\n",
        "    # eval_dataset=eval_hf,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "H7cmuj5CQ8C1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Получить один пример и преобразовать в правильный формат\n",
        "sample = train_hf[0]\n",
        "print(f\"Sample keys: {sample.keys()}\")\n",
        "\n",
        "# Преобразовать в тензоры и добавить batch dimension\n",
        "import torch\n",
        "\n",
        "inputs = {\n",
        "    \"input_values\": torch.tensor(sample[\"input_values\"]).unsqueeze(0),  # добавляем batch dim\n",
        "    \"labels\": torch.tensor(sample[\"labels\"]).unsqueeze(0)\n",
        "}\n",
        "\n",
        "print(f\"Input shapes: {inputs['input_values'].shape}\")\n",
        "print(f\"Label shapes: {inputs['labels'].shape}\")\n",
        "\n",
        "# Теперь проверить loss\n",
        "outputs = model(**inputs)\n",
        "print(f\"Loss из модели: {outputs.loss}\")\n",
        "\n",
        "\n",
        "## СКОРЕЕ ВСЕГО ПРОБЛЕМА В ТОМ ЧТО ДАННЫЕ НА cpu а модель на gpu!!"
      ],
      "metadata": {
        "trusted": true,
        "id": "EBdMOozHQ8C1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Dz4xdK-MQ8C1"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}