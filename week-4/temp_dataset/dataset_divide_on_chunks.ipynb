{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets==3.6.0\n",
        "from huggingface_hub import login\n",
        "login(\"\")"
      ],
      "metadata": {
        "id": "h2sw9dm0JgMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset, Audio, concatenate_datasets, DatasetDict"
      ],
      "metadata": {
        "id": "RYk5HPiqJt_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"Elormiden/rik_atn_global\", streaming=True)"
      ],
      "metadata": {
        "id": "hpLlhtYEJuJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "VC0lAYrOJwU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "def sample_and_chunk_dataset(ds: DatasetDict, fraction: float = 1/3, chunk_duration: float = 7.0, seed: int = 42) -> DatasetDict:\n",
        "    random.seed(seed)\n",
        "    total_rows = 125  # Original dataset size\n",
        "    sample_size = int(total_rows * fraction)\n",
        "    indices = random.sample(range(total_rows), sample_size)\n",
        "    indices.sort()\n",
        "\n",
        "    def chunk_generator():\n",
        "        current_idx = 0\n",
        "        for i, example in enumerate(tqdm(ds['train'], desc=\"Processing audio files\")):\n",
        "            if current_idx < len(indices) and i == indices[current_idx]:\n",
        "                audio_array = example['audio']['array']\n",
        "                sampling_rate = example['audio']['sampling_rate']\n",
        "                chunk_samples = int(chunk_duration * sampling_rate)\n",
        "                for j in range(0, len(audio_array), chunk_samples):\n",
        "                    chunk = audio_array[j:j + chunk_samples]\n",
        "                    if len(chunk) == chunk_samples:\n",
        "                        yield {'audio': {'array': chunk, 'sampling_rate': sampling_rate}}\n",
        "                current_idx += 1\n",
        "\n",
        "    # Create and return new DatasetDict\n",
        "    return DatasetDict({'train': Dataset.from_generator(chunk_generator)})"
      ],
      "metadata": {
        "id": "I0ioW65OJxeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_ds = sample_and_chunk_dataset(ds)"
      ],
      "metadata": {
        "id": "Rx3o-peVJ0Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_ds"
      ],
      "metadata": {
        "id": "cXj2V5wRh7mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_ds = new_ds.cast_column('audio', Audio(sampling_rate=16000))"
      ],
      "metadata": {
        "id": "H9o8zMeeh8CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_ds.push_to_hub(\"Elormiden/news-cut\")"
      ],
      "metadata": {
        "id": "TECm8mgqiRDz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}