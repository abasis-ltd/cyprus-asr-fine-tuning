{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUX96FbIcwYY"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets==3.6.0\n",
        "from huggingface_hub import login\n",
        "login(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhaHo037c7SW"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Dataset, Audio, concatenate_datasets, DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTn4xG2LdAJH"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset(\"Elormiden/RIK-cypriot-news-only\", streaming=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DtMwkbqdE0m"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "def sample_and_chunk_dataset(ds: DatasetDict, chunk_duration: float = 7.0, seed: int = 42) -> DatasetDict:\n",
        "    random.seed(seed)\n",
        "    total_rows = 125  # Original dataset size\n",
        "    indices = list(range(total_rows))\n",
        "\n",
        "    def chunk_generator():\n",
        "        current_idx = 0\n",
        "        for i, example in enumerate(tqdm(ds['train'], desc=\"Processing audio files\")):\n",
        "            if current_idx < len(indices) and i == indices[current_idx]:\n",
        "                audio_array = example['audio']['array']\n",
        "                sampling_rate = example['audio']['sampling_rate']\n",
        "                chunk_samples = int(chunk_duration * sampling_rate)\n",
        "                for j in range(0, len(audio_array), chunk_samples):\n",
        "                    chunk = audio_array[j:j + chunk_samples]\n",
        "                    if len(chunk) == chunk_samples:\n",
        "                        yield {'audio': {'array': chunk, 'sampling_rate': sampling_rate}}\n",
        "                current_idx += 1\n",
        "\n",
        "    # Create and return new DatasetDict\n",
        "    return DatasetDict({'train': Dataset.from_generator(chunk_generator)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHcxh1RHdJsO"
      },
      "outputs": [],
      "source": [
        "new_ds = sample_and_chunk_dataset(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QICbqSf2dbSx"
      },
      "outputs": [],
      "source": [
        "new_ds = new_ds.cast_column('audio', Audio(sampling_rate=16000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yowkSZT5hJYP"
      },
      "outputs": [],
      "source": [
        "new_ds.push_to_hub(\"Elormiden/only-news-shuffled-cut\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
