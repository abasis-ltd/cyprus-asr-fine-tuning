{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4667c3b8-935b-4013-8ae6-7c4943d7ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets==3.6.0\n",
    "# !pip install transformers\n",
    "# !pip install tf-keras\n",
    "# !pip install torch\n",
    "# !pip install transformers[torch]\n",
    "# !pip install wandb\n",
    "# !pip install evaluate\n",
    "# !pip install librosa\n",
    "# !pip install jiwer\n",
    "# !pip install numpy==1.26.4\n",
    "# !pip install pyctcdecode\n",
    "# !pip install kenlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3035a856-9b63-440a-9521-bad19757b8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2025-08-06 08:47:00.540883: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754470020.560326   16671 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754470020.566514   16671 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754470020.585322   16671 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754470020.585341   16671 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754470020.585343   16671 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754470020.585345   16671 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import torch\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "import kenlm\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Union, Optional\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset, Audio, disable_caching\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    AutoModelForCTC,\n",
    "    Wav2Vec2Processor,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ec6736-e80a-4839-88f3-cfa23d06c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2e5f51-ec07-4ffc-ae4f-2c7e6bb67aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Elormiden/1.05-0.9-0.55-full\")\n",
    "model = AutoModelForCTC.from_pretrained(\"Elormiden/1.05-0.9-0.55-full\").eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bf14b9c6-779c-42fe-a989-7bff4b8c80d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully.\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 34065\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 4255\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 4279\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, Audio\n",
    "\n",
    "# ====================================================================================\n",
    "# Data Loading and Resampling\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "ds = load_dataset(\"Elormiden/RIK_Cypriot_News_Dataset\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(ds)\n",
    "\n",
    "# We will use all splits for a complete workflow\n",
    "train_ds = ds['train']\n",
    "eval_ds = ds['validation']\n",
    "test_ds = ds['test']\n",
    "\n",
    "debug_ds = ds['test'].select(range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a6f821d4-3c5d-4d6b-93ae-96cfe7c32305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, processor, test_dataset, batch_size=30):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_dataset), batch_size):\n",
    "            batch = test_dataset[i:i+batch_size]\n",
    "            \n",
    "            audio_arrays = [sample[\"array\"] for sample in batch[\"audio\"]]\n",
    "            inputs = processor(\n",
    "                audio_arrays, \n",
    "                sampling_rate=16000, \n",
    "                return_tensors=\"pt\", \n",
    "                padding=True\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            logits = model(**inputs).logits\n",
    "\n",
    "            # logits[:, :, 53] = -float('inf') # only for my trained models\n",
    "            \n",
    "            predicted_ids = torch.argmax(logits, dim=-1)\n",
    "            predictions = processor.batch_decode(predicted_ids)\n",
    "            \n",
    "            all_predictions.extend(predictions)\n",
    "            all_references.extend(batch[\"text\"])\n",
    "            \n",
    "            if i % (batch_size * 10) == 0:\n",
    "                print(f\"Processed {i}/{len(test_dataset)} samples\")\n",
    "    \n",
    "    wer = wer_metric.compute(predictions=all_predictions, references=all_references)\n",
    "    \n",
    "    return wer, all_predictions, all_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aebd2214-812c-427a-9ace-ce3e38fcb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "\n",
    "base_processor = AutoProcessor.from_pretrained(\"jonatasgrosman/wav2vec2-large-xlsr-53-greek\")\n",
    "base_model = AutoModelForCTC.from_pretrained(\"jonatasgrosman/wav2vec2-large-xlsr-53-greek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "30fff04c-faff-4670-9e66-ce323a8357ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching tests...\n",
      "Processed 0/4255 samples\n",
      "Processed 300/4255 samples\n",
      "Processed 600/4255 samples\n",
      "Processed 900/4255 samples\n",
      "Processed 1200/4255 samples\n",
      "Processed 1500/4255 samples\n",
      "Processed 1800/4255 samples\n",
      "Processed 2100/4255 samples\n",
      "Processed 2400/4255 samples\n",
      "Processed 2700/4255 samples\n",
      "Processed 3000/4255 samples\n",
      "Processed 3300/4255 samples\n",
      "Processed 3600/4255 samples\n",
      "Processed 3900/4255 samples\n",
      "Processed 4200/4255 samples\n",
      "\n",
      "Test WER: 1.0309\n",
      "Test samples: 4279\n",
      "\n",
      "Sample predictions:\n",
      "Reference: Και το Τμήμα Ενόπλων και τους βουλευτές και τις οργανώσεις να έχουν μια συνάντηση την Τετάρτη τη μία ώρα εξέβησης στην αίθουσα του Δήμου Π.\n",
      "Predicted: ΡΕ ΤΟ ΤΣΊΜΠΑΛΙΆ ΤΟ ΚΑΙ ΤΟΥΝ ΔΟΥΛΕΥΤΑΊΣ ΚΑΙ ΤΙΣ ΣΤΟΡΓΑΛΏΣ Ή ΝΑ ΈΧΟΥ ΠΙΑΝ ΣΥΝΆΝΤΙΣΗ ΤΗ ΝΤΕΤΆΡΤΗΡΗ ΏΡΑ ΕΞΈΠΗΣΗ ΣΤΗΝ ΑΊΘΟΥ ΣΑΝ ΤΟΥ ΙΜΟΥ Έ\n",
      "--------------------------------------------------\n",
      "Reference: Τα μετάλλια. Εξαιρετική ήταν η χθεσινή μέρα στην ενόργανη γυμναστική, εκεί όπου ουσιαστικά σαρώσαμε δύο.\n",
      "Predicted: ΝΤΑ ΜΕΤΆΛΕΙΑ ΉΞΕΡΕΤΙ ΚΑΊ ΑΝΗΧΘΕΣΙΝΉΜΕΡΑ ΣΚΙΕΝΌΡΓΆΝΑ ΓΙΠΝΑ ΚΙΜΝΑΣΤΙΚΈ ΚΑΙ ΌΠΟΥ ΠΟΥ ΖΙΑΣΤΙΚΆ ΑΣΑΛΏΣΑΜΕ ΔΥ\n",
      "--------------------------------------------------\n",
      "Reference: Και όχι έμμεση, με δηλώσεις με αντιαεροπορική κάλυψη κτλ. Απευθείας εμπλοκή.\n",
      "Predicted: ΚΙ ΌΧΙ ΈΜΕΣΗ ΜΕ ΔΗΛΏΣΕΗΣ ΜΕ ΑΝΤΙΟΡΟΠΟΡΓΉ ΚΆΛΙΨΗ ΚΑΙ ΤΑ ΒΙΔΆ ΆΠΕ ΥΤΊΑΣ ΕΜΠΛΟΚΉ\n",
      "--------------------------------------------------\n",
      "Reference: Η Τουρκία που τους παρέχει ακριβώς ηλεκτρονική ασφάλεια. Υπάρχουν διάφορα αυτοματοποιημένα συστήματα.\n",
      "Predicted: ΕΣΊΑ ΠΟΥ ΤΟΥΣ ΠΑΡΑΈΧΕΙ ΑΚΡΙΒΏΣ Ή ΛΕΧΤΡΟΝΙΚΟΉ ΑΣΦΆΛΕΙΑ ΥΠΆΡΧΟΥΝ ΔΙΆΦΟΡΑ ΑΥΤΟΜΑΤΟΠΗΜΈΝΑ ΣΥΣΤΉΜΑΤ\n",
      "--------------------------------------------------\n",
      "Reference: Μας; Να ξέρει ο κόσμος την αλήθεια δηλαδή; Ναι. Και τι κάνουμε; Ναι.\n",
      "Predicted: ΜΑΣ ΝΑ ΞΈΡΕΙ Ο ΚΌΣΜΑΣ ΤΗΝ ΑΛΉΘΕΙΑ ΤΕ ΝΑΙΚΑΙ ΤΙ ΚΆΝΑΙ\n",
      "--------------------------------------------------\n",
      "Reference: Έχουν σήμερα για την προηπειρωτική, στόμα από την Πάφο ή από την πόλη Χρυσοχούς, έρχονται στη Λευκωσία.\n",
      "Predicted: ΣΉΜΕΝΑ ΓΙΑ ΤΗΝ ΠΡΟΠΗΡΗΣΙΑΚΉ ΣΤΏΡΑ ΑΠΌ ΤΗΝ ΠΆΩΝΗ ΑΠΌ ΤΗΝ ΠΟΛΉ ΧΡΥΣΣΟΚΟΎΣΟΥ ΈΧΟΝΤΑΣ ΤΗ ΛΕΟΚΟΥΣΊΑ\n",
      "--------------------------------------------------\n",
      "Reference: Λοιπόν, πάμε να δούμε πώς αναλύουν οι ειδικοί τις εξελίξεις και την κρίση και τον πόλεμο. Εεε...\n",
      "Predicted: ΝΑΙ ΤΟΝ ΠΆΜΕ ΝΑ ΔΟΎΜΕ ΠΌΣ ΑΝΑΝΈΒΩΝΗ ΗΔΙΚΉ ΤΙΣΕΞΕΛΊΞΉΣΑΙ ΚΑΙ ΤΗΝ ΚΡΈΣΗ ΚΑΙ ΤΟΝ ΠΌΛΕΜΟΑ\n",
      "--------------------------------------------------\n",
      "Reference: Από τη στιγμή που πλέον έχουμε έναν ανοιχτό πόλεμο, ε, το Ισραήλ χτυπάει το Ιράν, ε, το Ιράν χτυπάει με βαλλιστικούς πυραύλους, ε,\n",
      "Predicted: Ο ΔΕΣΤΙΓΜΉ ΠΟΥΚΛΟΎΜΙΑΣ Μ' ΈΝΑΝΟΙΧΤΌΝ ΠΌΛΕΜΟ Ε ΤΟ ΤΖΩΈ Δ ΤΗΝ ΠΆΓΕΙ ΤΩΉΡΑ ΝΑΕΤΗΡΆΛΛΟ ΤΥΠΕΥΑΛΕΣΤΙΚΟΎΣ ΠΥΡΑΎΛΟΥΣΕ\n",
      "--------------------------------------------------\n",
      "Reference: Στιγμή να αποδεχτεί τη συμφωνία που του έχει προτείνει ο Τραμπ, η οποία είναι περίπου πρέπει να πω αυτή.\n",
      "Predicted: ΕΣΤΙΓΜΉΝΑ ΑΠΌ ΚΑΙΒΟΉ ΤΗΝ ΤΗΝ ΣΥΜΦΩΝΊΑ ΠΟΥ ΤΟΥ ΈΧΕΙ ΠΡΟΤΕΊΝΕΙΩ ΤΡΆΜΠΗ ΟΠΟΊΑ ΕΊΝΑΙ ΠΕΡΊΠΗ ΠΡΈΠΕΙ ΝΑ ΠΥ ΑΥΤΉ\n",
      "--------------------------------------------------\n",
      "Reference: Με τον ιρανικό λαό. Και ένας από τους δύο στόχους της ισραηλινής επίθεσης, ότι έχουν.\n",
      "Predicted: ΒΙ ΜΕ ΤΟΝ ΙΡΑΝΙΚΌ ΕΝΑ ΏΝ ΚΑΙ  ΈΝΑΣ ΑΠΌ ΤΟΥΣ ΔΎΟΣ ΤΌΧΟΥΣ ΣΕΔΑΤΉΣΕΣ ΣΙΔΕΡΈΝΕΜΙΣ ΕΠΊΤΗ ΤΟΥ ΤΟ ΚΟΥΓΠ\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Launching tests...')\n",
    "wer_score, predictions, references = evaluate_model(base_model, base_processor, eval_ds)\n",
    "\n",
    "print(f\"\\nTest WER: {wer_score:.4f}\")\n",
    "print(f\"Test samples: {len(test_ds)}\")\n",
    "\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(10):\n",
    "    print(f\"Reference: {references[i]}\")\n",
    "    print(f\"Predicted: {predictions[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6760bcf6-f253-4cd8-afc1-c4fc84db13c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "57\n",
      "{\"'\": 49, '[PAD]': 54, '[UNK]': 53, 'a': 16, 'e': 12, 'g': 10, 'h': 46, 'm': 4, 'n': 29, 'o': 40, 'r': 20, 't': 6, 'v': 50, '|': 30, '«': 25, '´': 11, '·': 23, '»': 24, '́': 52, 'ΐ': 14, 'ά': 34, 'έ': 36, 'ή': 42, 'ί': 48, 'α': 47, 'β': 26, 'γ': 33, 'δ': 18, 'ε': 44, 'ζ': 19, 'η': 32, 'θ': 22, 'ι': 45, 'κ': 27, 'λ': 21, 'μ': 38, 'ν': 28, 'ξ': 41, 'ο': 5, 'π': 3, 'ρ': 1, 'ς': 39, 'σ': 8, 'τ': 17, 'υ': 51, 'φ': 2, 'χ': 31, 'ψ': 0, 'ω': 35, 'ϊ': 9, 'ϋ': 7, 'ό': 37, 'ύ': 13, 'ώ': 43, '’': 15, '<s>': 55, '</s>': 56}\n"
     ]
    }
   ],
   "source": [
    "vocab = processor.tokenizer.get_vocab()\n",
    "\n",
    "kenlm_vocab = []\n",
    "for token, idx in sorted(vocab.items(), key=lambda x: x[1]):\n",
    "    if idx not in [55, 56]:  # тупые служебные токены <s> и </s>!!!\n",
    "        kenlm_vocab.append(token)\n",
    "\n",
    "print(len(kenlm_vocab))\n",
    "print(len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a4223fe0-e1be-4523-80b3-594ce189d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_kenlm(model, processor, test_dataset, lm_path, batch_size=20, alpha=0.5, beta=1.0):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Настройка декодера с KenLM\n",
    "    # vocab_dict = kenlm_vocab\n",
    "    # sorted_vocab_list = [\n",
    "    #     key for key, value in sorted(vocab_dict.items(), key=lambda item: item[1])\n",
    "    # ]\n",
    "    \n",
    "    decoder = build_ctcdecoder(\n",
    "        labels=kenlm_vocab,\n",
    "        kenlm_model_path=lm_path,\n",
    "        alpha=alpha,\n",
    "        beta=beta\n",
    "    )\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_dataset), batch_size):\n",
    "            batch = test_dataset[i:i+batch_size]\n",
    "            \n",
    "            audio_arrays = [sample[\"array\"] for sample in batch[\"audio\"]]\n",
    "            inputs = processor(\n",
    "                audio_arrays, \n",
    "                sampling_rate=16000, \n",
    "                return_tensors=\"pt\", \n",
    "                padding=True\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            logits = model(**inputs).logits\n",
    "            \n",
    "            # ВАЖНО: тот же фильтр что и в оригинале\n",
    "            logits[:, :, 53] = -float('inf')\n",
    "            \n",
    "            # Для KenLM нужны log probabilities\n",
    "            logits = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "            logits_numpy = logits.cpu().numpy()\n",
    "            \n",
    "            # Декодируем с KenLM\n",
    "            batch_predictions = []\n",
    "            for j in range(logits_numpy.shape[0]):\n",
    "                single_logits = logits_numpy[j]\n",
    "                prediction = decoder.decode(single_logits)\n",
    "                batch_predictions.append(prediction)\n",
    "            \n",
    "            all_predictions.extend(batch_predictions)\n",
    "            all_references.extend(batch[\"text\"])  # Как в оригинале\n",
    "            \n",
    "            if i % (batch_size * 10) == 0:\n",
    "                print(f\"Processed {i}/{len(test_dataset)} samples\")\n",
    "    \n",
    "    wer = wer_metric.compute(predictions=all_predictions, references=all_references)\n",
    "    \n",
    "    return wer, all_predictions, all_references\n",
    "\n",
    "# Запуск\n",
    "lm_path = './cypriot.klm'  # Путь к твоей KenLM модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2aa11a63-faeb-4204-8b1d-62e1bb187bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
      "No known unigrams provided, decoding results might be a lot worse.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching tests with KenLM support...\n",
      "Processed 0/4255 samples\n",
      "Processed 200/4255 samples\n",
      "Processed 400/4255 samples\n",
      "Processed 600/4255 samples\n",
      "Processed 800/4255 samples\n",
      "Processed 1000/4255 samples\n",
      "Processed 1200/4255 samples\n",
      "Processed 1400/4255 samples\n",
      "Processed 1600/4255 samples\n",
      "Processed 1800/4255 samples\n",
      "Processed 2000/4255 samples\n",
      "Processed 2200/4255 samples\n",
      "Processed 2400/4255 samples\n",
      "Processed 2600/4255 samples\n",
      "Processed 2800/4255 samples\n",
      "Processed 3000/4255 samples\n",
      "Processed 3200/4255 samples\n",
      "Processed 3400/4255 samples\n",
      "Processed 3600/4255 samples\n",
      "Processed 3800/4255 samples\n",
      "Processed 4000/4255 samples\n",
      "Processed 4200/4255 samples\n",
      "\n",
      "Test WER: 0.5469\n",
      "Test samples: 4279\n",
      "\n",
      "Sample predictions:\n",
      "Reference: Και το Τμήμα Ενόπλων και τους βουλευτές και τις οργανώσεις να έχουν μια συνάντηση την Τετάρτη τη μία ώρα εξέβησης στην αίθουσα του Δήμου Π.\n",
      "Predicted: και το τπαδάτωκαιτους δουλευτές και τις δοογανώσεις να έχουν μια συνάντηση την τετάρτη ώρα εξέπισηςστην αίθουσα του δήμου\n",
      "--------------------------------------------------\n",
      "Reference: Τα μετάλλια. Εξαιρετική ήταν η χθεσινή μέρα στην ενόργανη γυμναστική, εκεί όπου ουσιαστικά σαρώσαμε δύο.\n",
      "Predicted: τα μετάλλια εξαιρετική ραμηθεσινήμερα στην ενόργανη γυμναστική εκεί όπου ουσιαστικά σαρώσαμε τι\n",
      "--------------------------------------------------\n",
      "Reference: Και όχι έμμεση, με δηλώσεις με αντιαεροπορική κάλυψη κτλ. Απευθείας εμπλοκή.\n",
      "Predicted: και όχι έμμεση με δηλώσεις με αντιεροπωρική κάλυψη και τα λοιπά απευθείας εμπλοκή\n",
      "--------------------------------------------------\n",
      "Reference: Η Τουρκία που τους παρέχει ακριβώς ηλεκτρονική ασφάλεια. Υπάρχουν διάφορα αυτοματοποιημένα συστήματα.\n",
      "Predicted: που τους παρέχει ακριβώς ηλεκτρονική ασφάλεια υπάρχουν διάφορα αυτοματοποιημένα συστήματα\n",
      "--------------------------------------------------\n",
      "Reference: Μας; Να ξέρει ο κόσμος την αλήθεια δηλαδή; Ναι. Και τι κάνουμε; Ναι.\n",
      "Predicted: να ξέρει ο κόσμος την αλήθεια δηβατραναι και τι κάνουν ναι\n",
      "--------------------------------------------------\n",
      "Reference: Έχουν σήμερα για την προηπειρωτική, στόμα από την Πάφο ή από την πόλη Χρυσοχούς, έρχονται στη Λευκωσία.\n",
      "Predicted: έχουν σήμερα για την προϋπηρεσιακή στόπ από την πάχονηαπότην πόριχρυσοπούς έρχονται στην λευκωσία\n",
      "--------------------------------------------------\n",
      "Reference: Λοιπόν, πάμε να δούμε πώς αναλύουν οι ειδικοί τις εξελίξεις και την κρίση και τον πόλεμο. Εεε...\n",
      "Predicted: λοιπόν πάμε να δούμε πόσο να λέει ον δική της εξελίξεις και την κρίση και τον πόλεμο\n",
      "--------------------------------------------------\n",
      "Reference: Από τη στιγμή που πλέον έχουμε έναν ανοιχτό πόλεμο, ε, το Ισραήλ χτυπάει το Ιράν, ε, το Ιράν χτυπάει με βαλλιστικούς πυραύλους, ε,\n",
      "Predicted: τη στιγμή που πλέον έχουμε νανεκτόπόδεμο το ισραήηπάρτοήρα το ιράνοτηπεβαλιστικού πυραύλους\n",
      "--------------------------------------------------\n",
      "Reference: Στιγμή να αποδεχτεί τη συμφωνία που του έχει προτείνει ο Τραμπ, η οποία είναι περίπου πρέπει να πω αυτή.\n",
      "Predicted: στιγμή από συμφωνία που του έχει προτνιοτραμπη οποία είναι περίπου πρέπει να κό αυτή\n",
      "--------------------------------------------------\n",
      "Reference: Με τον ιρανικό λαό. Και ένας από τους δύο στόχους της ισραηλινής επίθεσης, ότι έχουν.\n",
      "Predicted: με τον ιρανικό λαών και ένας από τους δύο στόχους της ιγραηλμήςεπίθηκε το έχουν\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Launching tests with KenLM support...')\n",
    "wer_score, predictions, references = evaluate_model_kenlm(model, processor, eval_ds, lm_path)\n",
    "\n",
    "print(f\"\\nTest WER: {wer_score:.4f}\")\n",
    "print(f\"Test samples: {len(test_ds)}\")\n",
    "\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(10):\n",
    "    print(f\"Reference: {references[i]}\")\n",
    "    print(f\"Predicted: {predictions[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
